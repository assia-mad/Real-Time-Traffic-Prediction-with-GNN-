{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from stgcn import STGCN\n",
    "from utils import generate_dataset, load_metr_la_data, get_normalized_adj\n",
    "\n",
    "\n",
    "use_gpu = False\n",
    "num_timesteps_input = 12\n",
    "num_timesteps_output = 3\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "303e91f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookair/GNN_project/core/core.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m validation_maes \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_epoch(training_input, training_target, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     training_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     \u001b[39m# Run validation\u001b[39;00m\n",
      "\u001b[1;32m/Users/macbookair/GNN_project/core/core.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m X_batch \u001b[39m=\u001b[39m X_batch\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m out \u001b[39m=\u001b[39m net(A_wave, X_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_criterion(out, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/macbookair/GNN_project/core/core.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GNN_project/core/stgcn.py:128\u001b[0m, in \u001b[0;36mSTGCN.forward\u001b[0;34m(self, A_hat, X)\u001b[0m\n\u001b[1;32m    126\u001b[0m out1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock1(X, A_hat)\n\u001b[1;32m    127\u001b[0m out2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock2(out1, A_hat)\n\u001b[0;32m--> 128\u001b[0m out3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_temporal(out2)\n\u001b[1;32m    129\u001b[0m out4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully(out3\u001b[39m.\u001b[39mreshape((out3\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], out3\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m out4\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GNN_project/core/stgcn.py:36\u001b[0m, in \u001b[0;36mTimeBlock.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     34\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     35\u001b[0m temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(X) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(X))\n\u001b[0;32m---> 36\u001b[0m out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(temp \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(X))\n\u001b[1;32m     37\u001b[0m \u001b[39m# Convert back from NCHW to NHWC\u001b[39;00m\n\u001b[1;32m     38\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/GNN_project/devenv/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_epoch(training_input, training_target, batch_size):\n",
    "    \"\"\"\n",
    "    Trains one epoch with the given data.\n",
    "    :param training_input: Training inputs of shape (num_samples, num_nodes,\n",
    "    num_timesteps_train, num_features).\n",
    "    :param training_target: Training targets of shape (num_samples, num_nodes,\n",
    "    num_timesteps_predict).\n",
    "    :param batch_size: Batch size to use during training.\n",
    "    :return: Average loss for this epoch.\n",
    "    \"\"\"\n",
    "    permutation = torch.randperm(training_input.shape[0])\n",
    "\n",
    "    epoch_training_losses = []\n",
    "    for i in range(0, training_input.shape[0], batch_size):\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i : i + batch_size]\n",
    "        X_batch, y_batch = training_input[indices], training_target[indices]\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        y_batch = y_batch.to(device=device)\n",
    "\n",
    "        out = net(A_wave, X_batch)\n",
    "        loss = loss_criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_losses.append(loss.detach().cpu().numpy())\n",
    "    return sum(epoch_training_losses) / len(epoch_training_losses)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(7)\n",
    "\n",
    "    A, X, means, stds = load_metr_la_data()\n",
    "\n",
    "    split_line1 = int(X.shape[2] * 0.6)\n",
    "    split_line2 = int(X.shape[2] * 0.8)\n",
    "\n",
    "    train_original_data = X[:, :, :split_line1]\n",
    "    val_original_data = X[:, :, split_line1:split_line2]\n",
    "    test_original_data = X[:, :, split_line2:]\n",
    "\n",
    "    training_input, training_target = generate_dataset(\n",
    "        train_original_data,\n",
    "        num_timesteps_input=num_timesteps_input,\n",
    "        num_timesteps_output=num_timesteps_output,\n",
    "    )\n",
    "    val_input, val_target = generate_dataset(\n",
    "        val_original_data,\n",
    "        num_timesteps_input=num_timesteps_input,\n",
    "        num_timesteps_output=num_timesteps_output,\n",
    "    )\n",
    "    test_input, test_target = generate_dataset(\n",
    "        test_original_data,\n",
    "        num_timesteps_input=num_timesteps_input,\n",
    "        num_timesteps_output=num_timesteps_output,\n",
    "    )\n",
    "\n",
    "    A_wave = get_normalized_adj(A)\n",
    "    A_wave = torch.from_numpy(A_wave)\n",
    "\n",
    "    A_wave = A_wave.to(device=device)\n",
    "\n",
    "    net = STGCN(\n",
    "        A_wave.shape[0],\n",
    "        training_input.shape[3],\n",
    "        num_timesteps_input,\n",
    "        num_timesteps_output,\n",
    "    ).to(device=device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    loss_criterion = nn.MSELoss()\n",
    "\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    validation_maes = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(training_input, training_target, batch_size=batch_size)\n",
    "        training_losses.append(loss)\n",
    "\n",
    "        # Run validation\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_input = val_input.to(device=device)\n",
    "            val_target = val_target.to(device=device)\n",
    "\n",
    "            out = net(A_wave, val_input)\n",
    "            val_loss = loss_criterion(out, val_target).to(device=\"cpu\")\n",
    "            validation_losses.append(np.ndarray.item(val_loss.detach().numpy()))\n",
    "\n",
    "            out_unnormalized = out.detach().cpu().numpy() * stds[0] + means[0]\n",
    "            target_unnormalized = val_target.detach().cpu().numpy() * stds[0] + means[0]\n",
    "            mae = np.mean(np.absolute(out_unnormalized - target_unnormalized))\n",
    "            validation_maes.append(mae)\n",
    "\n",
    "            out = None\n",
    "            val_input = val_input.to(device=\"cpu\")\n",
    "            val_target = val_target.to(device=\"cpu\")\n",
    "\n",
    "        print(\"Training loss: {}\".format(training_losses[-1]))\n",
    "        print(\"Validation loss: {}\".format(validation_losses[-1]))\n",
    "        print(\"Validation MAE: {}\".format(validation_maes[-1]))\n",
    "        print(\"Epoch: \", str(len(training_losses)))\n",
    "        print(\"===================================\")\n",
    "        checkpoint_path = \"checkpoints/\"\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        with open(\"checkpoints/losses.pk\", \"wb\") as fd:\n",
    "            pk.dump((training_losses, validation_losses, validation_maes), fd)\n",
    "    \n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27816aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model_save_path = os.path.join(checkpoint_path, \"model_final_state.pth\")\n",
    "torch.save(net.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6a7bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test validation Loss: 0.17831580340862274\n"
     ]
    }
   ],
   "source": [
    "#Test model \n",
    "net.eval()\n",
    "test_input = test_input.to(device=device)\n",
    "test_target = test_target.to(device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_output = net(A_wave, test_input)\n",
    "test_loss = loss_criterion(test_output, test_target).item()\n",
    "print(f\"Test validation Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d4041f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Absolute Error: 4.329678535461426\n"
     ]
    }
   ],
   "source": [
    "test_output_unnormalized = test_output.detach().cpu().numpy() * stds[0] + means[0]\n",
    "test_target_unnormalized = test_target.detach().cpu().numpy() * stds[0] + means[0]\n",
    "# Calculate Mean Absolute Error\n",
    "test_mae = np.mean(np.absolute(test_output_unnormalized - test_target_unnormalized))\n",
    "print(f\"Test Mean Absolute Error: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fdd3b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted speeds for the first location for three consecutive future time steps: [65.298004 65.15281  65.0161  ]\n",
      "Acutal speeds for the first location for three consecutive futre time stpes:  [67.125    63.333332 65.375   ]\n"
     ]
    }
   ],
   "source": [
    "#Make prediction \n",
    "net = STGCN(\n",
    "    A_wave.shape[0],\n",
    "    training_input.shape[3],\n",
    "    num_timesteps_input,\n",
    "    num_timesteps_output,\n",
    ").to(device=device)\n",
    "\n",
    "# Load the saved model parameters\n",
    "model_save_path = 'checkpoints/model_final_state.pth'  # Update this path\n",
    "net.load_state_dict(torch.load(model_save_path))\n",
    "net.eval()\n",
    "test_input = test_input.to(device=device)\n",
    "test_target = test_target.to(device=device)\n",
    "with torch.no_grad():\n",
    "    test_predictions = net(A_wave, test_input)\n",
    "test_predictions_unnormalized = test_predictions.cpu().numpy() * stds[0] + means[0]\n",
    "\n",
    "#Print the predictions\n",
    "print(\"Predicted speeds for the first location for three consecutive future time steps:\", test_predictions_unnormalized[0, 0, :])\n",
    "print(\"Actual speeds for the first location for three consecutive futre time stpes: \", test_target_unnormalized[0, 0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
